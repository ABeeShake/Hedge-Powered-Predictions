View(r)
import torch
y = torch.ones(1,19)
y.size(1)
import ExpMethods.models as m
import ExpMethods.data as data
import ExpMethods.utils as utils
import ExpMethods.visualizations as viz
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import lightning as L
import torch.nn as nn
from torchdyn.core import NeuralODE
from torchdyn.nn import DepthCat
from lightning.pytorch.callbacks import EarlyStopping,ModelCheckpoint
L.seed_everything(723)
raw_data = pd.read_csv("./minute_data/CGMacros-001-clean.csv")
df = data.transform_minute_data(raw_data, n_days = 1, return_type = pd.DataFrame)
X = torch.tensor(df.to_numpy()).to(torch.float32)
max_horizon = 30
max_batch_size = 10
t_start = 20
t_end = len(X) - max_horizon
max_epochs = 3
N, d = X.shape
node_params = dict(
input_dim = d,
hidden_dim = 64,
output_dim = d,
horizon = max_horizon,
sensitivity = "adjoint",
solver = "dopri5"
)
lstm_params = dict(
input_dim = d,
hidden_dim = 20,
n_layers = 1,
horizon = max_horizon
)
callbacks = [
ModelCheckpoint(save_top_k=1, mode="min", monitor="loss"),
EarlyStopping(monitor = "loss", mode = "min", stopping_threshold = 1)
]
trainer_params = dict(
max_epochs = 100,
#    callbacks = callbacks, #(define callbacks)
#    strategy = "ddp" #(use if multiple GPUs are available)
accelerator = "auto",
precision = "16", #(use mixed precision)
devices = 1,
log_every_n_steps = 1,
#    auto_lr_find = True, #(chooses learning rate automatically (DEPRECATED))
deterministic = True, #(reproducibility)
#    enable_progress_bar = False,
#    enable_model_summary = False
)
node = m.NODEForecaster(m.NODE(**node_params))
lstm = m.LSTMForecaster(m.LSTM(**lstm_params))
model_dict = dict(
node = node,
lstm = lstm
)
import sys
import sys
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import lightning as L
import torch.nn as nn
from torchdyn.core import NeuralODE
from torchdyn.nn import DepthCat
from lightning.pytorch.callbacks import EarlyStopping,ModelCheckpoint
sys.path.append("/home/abhishekdevarajan/Simulation-Scripts/Hedge-Powered-Predictions/ExpMethods/")
import ExpMethods.models as m
import ExpMethods.data as data
import ExpMethods.utils as utils
import ExpMethods.visualizations as viz
import os
os.getcwd()
os.chdir("./Simulation-Scripts/Hedge-Powered-Predictions/")
import ExpMethods.data as data
import ExpMethods.models as m
def get_data(path):
raw_data = pd.read_csv(path)
df = data.transform_minute_data(raw_data, return_type = pd.DataFrame)
X = torch.tensor(df.to_numpy()).to(torch.float32)
return df, X
path = "../minute_data/CGMacros-001-clean.csv"
df, X = get_data(path)
t = 100
x_train = df.iloc[:t,:]
x_test = df.iloc[t:,:]
data_params = dict(
x_train = df.iloc[:t,:],
x_test = df.iloc[t:,:],
batch_size = b,
max_horizon = h,
h_first = True
)
data_params = dict(
x_train = df.iloc[:t,:],
x_test = df.iloc[t:,:],
batch_size = 30,
max_horizon = 1,
h_first = True
)
data_module = data.MinuteDataLightningDataModule(**data_params)
next(iter(data_module))
next(iter(data_module.train_dataloader))
next(iter(data_module.train_dataloader()))
data_module.setup()
next(iter(data_module.train_dataloader()))
xb,yb = next(iter(data_module.train_dataloader()))
yb.shape
data_params = dict(
x_train = df.iloc[:t,:],
x_test = df.iloc[t:,:],
batch_size = 30,
max_horizon = 100,
h_first = True
)
data_module = data.MinuteDataLightningDataModule(**data_params)
data_module.setup()
xb,yb = next(iter(data_module.train_dataloader()))
yb.shape
torch.ones(1).shape
data_params = dict(
x_train = df.iloc[:20,:],
x_test = df.iloc[20:,:],
batch_size = 32,
max_horizon = 30,
h_first = True
)
data_module = data.MinuteDataLightningDataModule(**data_params)
data_module.setup()
xb,yb = next(iter(data_module.train_dataloader()))
yb.shape
lstm = m.LSTMForecaster(m.LSTM(**lstm_params))
lstm_params = dict(
input_dim = X.shape[1],
hidden_dim = 50,
n_layers = 1,
horizon = 30
)
lstm = m.LSTMForecaster(m.LSTM(**lstm_params))
lstm.training_step(bath = (xb,yb), batch_idx = 1)
lstm.training_step(batch = (xb,yb), batch_idx = 1)
lstm.training_step(batch = (xb,yb), batch_idx = 1)
import ExpMethods.models as m
lstm = m.LSTMForecaster(m.LSTM(**lstm_params))
lstm.training_step(batch = (xb,yb), batch_idx = 1)
data_params = dict(
x_train = df.iloc[:20,:],
x_test = df.iloc[20:,:],
batch_size = 32,
max_horizon = 1,
h_first = True
)
data_module = data.MinuteDataLightningDataModule(**data_params)
data_module.setup()
xb,yb = next(iter(data_module.train_dataloader()))
yb.shape
lstm.training_step(batch = (xb,yb), batch_idx = 1)
node_params = dict(
input_dim = X.shape[1],
hidden_dim = 64,
output_dim = X.shape[1],
horizon = 30,
sensitivity = "adjoint",
solver = "dopri5"
)
node = m.NODEForecaster(m.NODE(**node_params))
node.training_step(batch = (xb,yb), batch_idx = 1)
node(xb)
node(xb).shape
node(xb)[1].shape
yb.shape
dict(zip(["a","b","c"], np.arange(9).reshape(3,3)))
dict(zip(["a","b","c"], np.arange(9).reshape(3,3).T))
import ExpMethods.simulate as sim
f = dict(zip(["m1","m2"],np.random.rand(100,2).T))
f
f["m1"]
targets = np.random.rand(100) * np.random.choice(np.arange(1,5))
sim.get_online_losses(forecasts, targets, start = 20, horizon = 10)
l = sim.get_online_losses(f, targets, start = 20, horizon = 10)
l
em = get_weighted_forecasts(forecasts, losses, targets, start = 20, horizon = 10, end = 100-10)
em = sim.get_weighted_forecasts(forecasts, losses, targets, start = 20, horizon = 10, end = 100-10)
em = sim.get_weighted_forecasts(f, l, targets, start = 20, horizon = 10, end = 100-10)
em = sim.get_weighted_forecasts(f, l, targets, start = 20, horizon = 10, end = 100-10)
import ExpMethods.simulate as sim
reticulate::repl_python()
